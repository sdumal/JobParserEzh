#!/usr/bin/env python3
"""
Job Monitor - –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –≤–∞–∫–∞–Ω—Å–∏–π —Å –æ—Ç–ø—Ä–∞–≤–∫–æ–π –≤ Telegram
–ê–≤—Ç–æ—Ä: Assistant
"""

import os
import json
import sqlite3
import logging
import asyncio
import argparse
import hashlib
from datetime import datetime, timedelta
from typing import List, Dict, Optional, Set
from dataclasses import dataclass, asdict
from urllib.parse import urljoin, urlparse
import aiohttp
import feedparser
from bs4 import BeautifulSoup
import schedule
import time
from dotenv import load_dotenv

# –ó–∞–≥—Ä—É–∑–∫–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è
load_dotenv()

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler('job_monitor.log')
    ]
)
logger = logging.getLogger(__name__)

@dataclass
class Job:
    """–°—Ç—Ä—É–∫—Ç—É—Ä–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –≤–∞–∫–∞–Ω—Å–∏–∏"""
    title: str
    description: str
    link: str
    source: str
    location: str = ""
    company: str = ""
    tags: str = ""
    published: Optional[datetime] = None
    created_at: datetime = None
    
    def __post_init__(self):
        if self.created_at is None:
            self.created_at = datetime.now()
    
    def to_dict(self) -> Dict:
        """–ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –≤ —Å–ª–æ–≤–∞—Ä—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≤ –ë–î"""
        data = asdict(self)
        if self.published:
            data['published'] = self.published.isoformat()
        if self.created_at:
            data['created_at'] = self.created_at.isoformat()
        return data
    
    def get_hash(self) -> str:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —É–Ω–∏–∫–∞–ª—å–Ω–æ–≥–æ —Ö–µ—à–∞ –¥–ª—è –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏–∏"""
        unique_string = f"{self.title}|{self.link}|{self.source}"
        return hashlib.md5(unique_string.encode()).hexdigest()

class JobLocationFilter:
    """–§–∏–ª—å—Ç—Ä –≤–∞–∫–∞–Ω—Å–∏–π –ø–æ –º–µ—Å—Ç–æ–ø–æ–ª–æ–∂–µ–Ω–∏—é"""

    def __init__(self, allowed_locations: List[str]):
        # –ü—Ä–∏–≤–æ–¥–∏–º –≤—Å–µ —Ä–∞–∑—Ä–µ—à–µ–Ω–Ω—ã–µ –ª–æ–∫–∞—Ü–∏–∏ –∫ –Ω–∏–∂–Ω–µ–º—É —Ä–µ–≥–∏—Å—Ç—Ä—É –¥–ª—è —É–¥–æ–±—Å—Ç–≤–∞ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
        self.allowed_locations = [loc.lower() for loc in allowed_locations]

    def is_location_allowed(self, job: Job) -> bool:
        location = (job.location or '').lower()
        return any(allowed in location for allowed in self.allowed_locations)

class DatabaseManager:
    """–ú–µ–Ω–µ–¥–∂–µ—Ä –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö SQLite"""
    
    def __init__(self, db_path: str = "jobs.db"):
        self.db_path = db_path
        self.init_db()
    
    def init_db(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö"""
        with sqlite3.connect(self.db_path) as conn:
            conn.execute("""
                CREATE TABLE IF NOT EXISTS jobs (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    title TEXT NOT NULL,
                    description TEXT,
                    link TEXT NOT NULL,
                    source TEXT NOT NULL,
                    location TEXT,
                    company TEXT,
                    tags TEXT,
                    published TEXT,
                    created_at TEXT NOT NULL,
                    hash TEXT UNIQUE NOT NULL,
                    sent_to_telegram BOOLEAN DEFAULT FALSE
                )
            """)
            conn.execute("CREATE INDEX IF NOT EXISTS idx_hash ON jobs(hash)")
            conn.execute("CREATE INDEX IF NOT EXISTS idx_created_at ON jobs(created_at)")
            conn.commit()
    
    def add_job(self, job: Job) -> bool:
        """–î–æ–±–∞–≤–ª–µ–Ω–∏–µ –≤–∞–∫–∞–Ω—Å–∏–∏ –≤ –ë–î. –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç True –µ—Å–ª–∏ –¥–æ–±–∞–≤–ª–µ–Ω–∞, False –µ—Å–ª–∏ –¥—É–±–ª–∏–∫–∞—Ç"""
        try:
            with sqlite3.connect(self.db_path) as conn:
                job_data = job.to_dict()
                job_data['hash'] = job.get_hash()
                
                conn.execute("""
                    INSERT INTO jobs (title, description, link, source, location, 
                                    company, tags, published, created_at, hash)
                    VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                """, (
                    job_data['title'], job_data['description'], job_data['link'],
                    job_data['source'], job_data['location'], job_data['company'],
                    job_data['tags'], job_data['published'], job_data['created_at'],
                    job_data['hash']
                ))
                conn.commit()
                return True
        except sqlite3.IntegrityError:
            # –î—É–±–ª–∏–∫–∞—Ç - —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
            return False
    
    def get_new_jobs(self, hours: int = 24) -> List[Job]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –Ω–æ–≤—ã—Ö –≤–∞–∫–∞–Ω—Å–∏–π –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ N —á–∞—Å–æ–≤"""
        cutoff_time = datetime.now() - timedelta(hours=hours)
        
        with sqlite3.connect(self.db_path) as conn:
            conn.row_factory = sqlite3.Row
            cursor = conn.execute("""
                SELECT * FROM jobs 
                WHERE created_at > ? AND sent_to_telegram = FALSE
                ORDER BY created_at DESC
            """, (cutoff_time.isoformat(),))
            
            jobs = []
            for row in cursor.fetchall():
                job = Job(
                    title=row['title'],
                    description=row['description'],
                    link=row['link'],
                    source=row['source'],
                    location=row['location'],
                    company=row['company'],
                    tags=row['tags'],
                    published=datetime.fromisoformat(row['published']) if row['published'] else None,
                    created_at=datetime.fromisoformat(row['created_at'])
                )
                jobs.append(job)
            
            return jobs
    
    def mark_as_sent(self, job_hashes: List[str]):
        """–û—Ç–º–µ—Ç–∏—Ç—å –≤–∞–∫–∞–Ω—Å–∏–∏ –∫–∞–∫ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–µ –≤ Telegram"""
        with sqlite3.connect(self.db_path) as conn:
            for job_hash in job_hashes:
                conn.execute("UPDATE jobs SET sent_to_telegram = TRUE WHERE hash = ?", (job_hash,))
            conn.commit()

class JobParser:
    """–ü–∞—Ä—Å–µ—Ä –≤–∞–∫–∞–Ω—Å–∏–π –∏–∑ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤"""
    
    def __init__(self, session: aiohttp.ClientSession):
        self.session = session
    
    async def parse_rss(self, url: str, source_name: str) -> List[Job]:
        """–ü–∞—Ä—Å–∏–Ω–≥ RSS-–ª–µ–Ω—Ç—ã"""
        try:
            async with self.session.get(url) as response:
                content = await response.text()
                
            feed = feedparser.parse(content)
            jobs = []
            
            for entry in feed.entries:
                job = Job(
                    title=entry.get('title', ''),
                    description=entry.get('description', ''),
                    link=entry.get('link', ''),
                    source=source_name,
                    published=datetime(*entry.published_parsed[:6]) if hasattr(entry, 'published_parsed') and entry.published_parsed else None
                )
                jobs.append(job)
            
            return jobs
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ RSS {url}: {e}")
            return []
    
    async def parse_html(self, url: str, source_name: str, selectors: Dict[str, str]) -> List[Job]: 
    #"""–ü–∞—Ä—Å–∏–Ω–≥ HTML-—Å—Ç—Ä–∞–Ω–∏—Ü—ã —Å –∫–∞—Å—Ç–æ–º–Ω—ã–º–∏ —Å–µ–ª–µ–∫—Ç–æ—Ä–∞–º–∏ (–∞–¥–∞–ø—Ç–∏—Ä–æ–≤–∞–Ω–æ –ø–æ–¥ DOU)"""
        try:
            headers = {"User-Agent": "Mozilla/5.0 (compatible; JobBot/1.0)"}
            async with self.session.get(url, headers=headers) as response:
                content = await response.text()

            soup = BeautifulSoup(content, 'html.parser')
            jobs = []

            # –ü–æ–∏—Å–∫ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–æ–≤ —Å –≤–∞–∫–∞–Ω—Å–∏—è–º–∏
            job_containers = soup.select(selectors.get('container', '.vacancy'))

            for container in job_containers:
                title_elem = container.select_one(selectors.get('title', 'div.title a.vt'))
                link_elem = title_elem  # –í DOU —Å—Å—ã–ª–∫–∞ –≤ —Ç–æ–º –∂–µ —ç–ª–µ–º–µ–Ω—Ç–µ, —á—Ç–æ –∏ –∑–∞–≥–æ–ª–æ–≤–æ–∫
                desc_elem = container.select_one(selectors.get('description', 'div.sh-info'))
                company_elem = desc_elem  # –í DOU –æ–ø–∏—Å–∞–Ω–∏–µ —Å–æ–¥–µ—Ä–∂–∏—Ç –∏ –∫–æ–º–ø–∞–Ω–∏—é
                location_elem = container.select_one(selectors.get('location', 'span.cities'))

                if title_elem and link_elem:
                    job = Job(
                        title=title_elem.get_text(strip=True),
                        description=desc_elem.get_text(strip=True) if desc_elem else '',
                        link=urljoin(url, link_elem.get('href', '')),
                        source=source_name,
                        company=company_elem.get_text(strip=True).split('‚Äî')[0] if company_elem else '',
                        location=location_elem.get_text(strip=True) if location_elem else ''
                    )
                    jobs.append(job)

            logger.info(f"{len(jobs)} –≤–∞–∫–∞–Ω—Å–∏–π –Ω–∞–π–¥–µ–Ω–æ –Ω–∞ {source_name}")
            return jobs

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ HTML {url}: {e}")
            return []


class JobFilter:
    """–§–∏–ª—å—Ç—Ä –≤–∞–∫–∞–Ω—Å–∏–π –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º"""
    
    def __init__(self, keywords: List[str]):
        self.keywords = [kw.lower() for kw in keywords]
    
    def matches(self, job: Job) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è –≤–∞–∫–∞–Ω—Å–∏–∏ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º"""
        text_to_check = f"{job.title} {job.description} {job.tags}".lower()
        return any(keyword in text_to_check for keyword in self.keywords)

class TelegramBot:
    """–ö–ª–∏–µ–Ω—Ç –¥–ª—è –æ—Ç–ø—Ä–∞–≤–∫–∏ —Å–æ–æ–±—â–µ–Ω–∏–π –≤ Telegram"""
    
    def __init__(self, token: str, chat_id: str, config: Dict = None):
        self.token = token
        self.chat_id = chat_id
        self.base_url = f"https://api.telegram.org/bot{token}"
        self.max_message_length = 4096
        self.config = config or {}
    
    async def send_message(self, text: str, parse_mode: str = "Markdown") -> bool:
        """–û—Ç–ø—Ä–∞–≤–∫–∞ —Å–æ–æ–±—â–µ–Ω–∏—è –≤ Telegram"""
        try:
            url = f"{self.base_url}/sendMessage"
            data = {
                "chat_id": self.chat_id,
                "text": text,
                "parse_mode": parse_mode,
                "disable_web_page_preview": True
            }
            
            async with aiohttp.ClientSession() as session:
                async with session.post(url, json=data) as response:
                    if response.status == 200:
                        return True
                    else:
                        logger.error(f"–û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ –≤ Telegram: {response.status}")
                        return False
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ —Å–æ–æ–±—â–µ–Ω–∏—è –≤ Telegram: {e}")
            return False
    
    def format_job_message(self, job: Job) -> str:
        """–§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Å–æ–æ–±—â–µ–Ω–∏—è –æ –≤–∞–∫–∞–Ω—Å–∏–∏"""
        location = f" üåç {job.location}" if job.location else ""
        company = f" üè¢ {job.company}" if job.company else ""
        
        message = f"üíº *{job.title}*{location}{company}\nüîó [–û—Ç–∫—Ä—ã—Ç—å –≤–∞–∫–∞–Ω—Å–∏—é]({job.link})"
        
        # –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –¥–ª–∏–Ω—ã —Å–æ–æ–±—â–µ–Ω–∏—è
        if len(message) > 4000:
            message = message[:4000] + "..."
        
        return message
    
    def create_digest(self, jobs: List[Job], stats: Dict) -> str:
        """–°–æ–∑–¥–∞–Ω–∏–µ –¥–∞–π–¥–∂–µ—Å—Ç–∞ —Å –≤–∞–∫–∞–Ω—Å–∏—è–º–∏"""
        if not jobs:
            return "üìã –ù–æ–≤—ã—Ö –≤–∞–∫–∞–Ω—Å–∏–π –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 24 —á–∞—Å–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ."
        
        # –ó–∞–≥–æ–ª–æ–≤–æ–∫ –¥–∞–π–¥–∂–µ—Å—Ç–∞
        header = f"""üìä *–î–∞–π–¥–∂–µ—Å—Ç –≤–∞–∫–∞–Ω—Å–∏–π –∑–∞ {datetime.now().strftime('%d.%m.%Y')}*

"""
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ (–µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω–∞ –≤ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏)
        if self.config.get('show_stats', True):
            header += f"""üîç –ü—Ä–æ—Å–º–æ—Ç—Ä–µ–Ω–æ: {stats['total_viewed']} –≤–∞–∫–∞–Ω—Å–∏–π
‚ûï –ù–∞–π–¥–µ–Ω–æ –Ω–æ–≤—ã—Ö: {stats['total_added']}
üì§ –í –¥–∞–π–¥–∂–µ—Å—Ç–µ: {len(jobs)}
‚è∞ –í—Ä–µ–º—è: {stats['start_time'].strftime('%H:%M:%S')}

‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ

"""
        
        # –ì—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ –≤–∞–∫–∞–Ω—Å–∏–π –ø–æ –∏—Å—Ç–æ—á–Ω–∏–∫–∞–º
        jobs_by_source = {}
        for job in jobs:
            if job.source not in jobs_by_source:
                jobs_by_source[job.source] = []
            jobs_by_source[job.source].append(job)
        
        # –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–∞–π–¥–∂–µ—Å—Ç–∞
        digest_parts = [header]
        max_jobs_per_source = self.config.get('max_jobs_per_source', 10)
        
        for source, source_jobs in jobs_by_source.items():
            source_section = f"üìÇ *{source}* ({len(source_jobs)} –≤–∞–∫–∞–Ω—Å–∏–π)\n"
            
            # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤–∞–∫–∞–Ω—Å–∏–π –Ω–∞ –∏—Å—Ç–æ—á–Ω–∏–∫
            displayed_jobs = source_jobs[:max_jobs_per_source]
            
            for i, job in enumerate(displayed_jobs, 1):
                location = ""
                company = ""
                
                if self.config.get('show_location', True) and job.location:
                    location = f" üåç {job.location}"
                
                if self.config.get('show_company', True) and job.company:
                    company = f" üè¢ {job.company}"
                
                job_line = f"{i}. [{job.title}]({job.link}){location}{company}\n"
                
                # –î–æ–±–∞–≤–ª—è–µ–º –æ–ø–∏—Å–∞–Ω–∏–µ –µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω–æ
                if self.config.get('include_description', False) and job.description:
                    desc_preview = job.description[:100] + "..." if len(job.description) > 100 else job.description
                    job_line += f"   _{desc_preview}_\n"
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ –ø—Ä–µ–≤—ã—Å–∏—Ç –ª–∏ –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ —ç—Ç–æ–π –≤–∞–∫–∞–Ω—Å–∏–∏ –ª–∏–º–∏—Ç
                test_digest = "".join(digest_parts) + source_section + job_line
                if len(test_digest) > self.max_message_length - 200:  # –û—Å—Ç–∞–≤–ª—è–µ–º –∑–∞–ø–∞—Å
                    if len(source_jobs) > len(displayed_jobs):
                        source_section += f"   ... –∏ –µ—â–µ {len(source_jobs) - i + 1} –≤–∞–∫–∞–Ω—Å–∏–π\n"
                    break
                else:
                    source_section += job_line
            
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Å–∫–æ–ª—å–∫–æ –≤–∞–∫–∞–Ω—Å–∏–π —Å–∫—Ä—ã—Ç–æ
            if len(source_jobs) > max_jobs_per_source:
                hidden_count = len(source_jobs) - max_jobs_per_source
                source_section += f"   ... –∏ –µ—â–µ {hidden_count} –≤–∞–∫–∞–Ω—Å–∏–π\n"
            
            source_section += "\n"
            digest_parts.append(source_section)
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ–±—â–∏–π —Ä–∞–∑–º–µ—Ä
            if len("".join(digest_parts)) > self.max_message_length - 200:
                digest_parts.append("üìù *–î–∞–π–¥–∂–µ—Å—Ç —Å–æ–∫—Ä–∞—â–µ–Ω –∏–∑-–∑–∞ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π Telegram*")
                break
        
        return "".join(digest_parts)
    
    async def send_digest(self, digest: str) -> bool:
        """–û—Ç–ø—Ä–∞–≤–∫–∞ –¥–∞–π–¥–∂–µ—Å—Ç–∞, —Ä–∞–∑–±–∏–≤–∞—è –Ω–∞ —á–∞—Å—Ç–∏ –µ—Å–ª–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ"""
        if len(digest) <= self.max_message_length:
            return await self.send_message(digest)
        
        # –ï—Å–ª–∏ –¥–∞–π–¥–∂–µ—Å—Ç —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã–π, —Ä–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ —á–∞—Å—Ç–∏
        success_count = 0
        parts = self.split_digest(digest)
        
        for i, part in enumerate(parts):
            part_header = f"üìã *–î–∞–π–¥–∂–µ—Å—Ç ({i+1}/{len(parts)})*\n\n" if len(parts) > 1 else ""
            message = part_header + part
            
            if await self.send_message(message):
                success_count += 1
            
            await asyncio.sleep(1)  # –ó–∞–¥–µ—Ä–∂–∫–∞ –º–µ–∂–¥—É —Å–æ–æ–±—â–µ–Ω–∏—è–º–∏
        
        return success_count == len(parts)
    
    def split_digest(self, digest: str) -> List[str]:
        """–†–∞–∑–±–∏–µ–Ω–∏–µ –¥–∞–π–¥–∂–µ—Å—Ç–∞ –Ω–∞ —á–∞—Å—Ç–∏ –ø–æ –∏—Å—Ç–æ—á–Ω–∏–∫–∞–º"""
        parts = []
        current_part = ""
        
        lines = digest.split('\n')
        
        for line in lines:
            test_part = current_part + line + '\n'
            
            if len(test_part) > self.max_message_length - 200:
                if current_part:
                    parts.append(current_part.strip())
                    current_part = line + '\n'
                else:
                    # –ï—Å–ª–∏ –¥–∞–∂–µ –æ–¥–Ω–∞ —Å—Ç—Ä–æ–∫–∞ —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω–∞—è
                    parts.append(line[:self.max_message_length - 200] + "...")
                    current_part = ""
            else:
                current_part = test_part
        
        if current_part:
            parts.append(current_part.strip())
        
        return parts

class JobMonitor:
    """–û—Å–Ω–æ–≤–Ω–æ–π –∫–ª–∞—Å—Å –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ –≤–∞–∫–∞–Ω—Å–∏–π"""
    
    def __init__(self):
        self.db = DatabaseManager()
        self.load_config()
        self.telegram_bot = TelegramBot(
            token=os.getenv('TELEGRAM_BOT_TOKEN'),
            chat_id=os.getenv('TELEGRAM_CHAT_ID'),
            config=self.config.get('telegram', {})
        )
        self.job_filter = JobFilter(self.keywords)
        self.location_filter = JobLocationFilter(["gdansk", "remote", "poland"])
        self.stats = {
            'total_viewed': 0,
            'total_added': 0,
            'start_time': datetime.now()
        }
    
    def load_config(self):
        """–ó–∞–≥—Ä—É–∑–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –∏–∑ —Ñ–∞–π–ª–æ–≤"""
        try:
            with open('resources.json', 'r', encoding='utf-8') as f:
                self.resources = json.load(f)
        except FileNotFoundError:
            logger.warning("–§–∞–π–ª resources.json –Ω–µ –Ω–∞–π–¥–µ–Ω. –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –ø—É—Å—Ç–æ–π —Å–ø–∏—Å–æ–∫.")
            self.resources = []
        
        try:
            with open('keywords.json', 'r', encoding='utf-8') as f:
                self.keywords = json.load(f)
        except FileNotFoundError:
            logger.warning("–§–∞–π–ª keywords.json –Ω–µ –Ω–∞–π–¥–µ–Ω. –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –ø—É—Å—Ç–æ–π —Å–ø–∏—Å–æ–∫.")
            self.keywords = []
        
        try:
            with open('config.json', 'r', encoding='utf-8') as f:
                self.config = json.load(f)
        except FileNotFoundError:
            logger.warning("–§–∞–π–ª config.json –Ω–µ –Ω–∞–π–¥–µ–Ω. –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é.")
            self.config = {
                "telegram": {
                    "digest_format": "grouped",
                    "max_jobs_per_source": 10,
                    "show_stats": True,
                    "show_company": True,
                    "show_location": True,
                    "include_description": False
                },
                "scheduler": {
                    "scan_interval_hours": 1,
                    "report_time": "09:00"
                }
            }
    
    async def scan_all_sources(self):
        """–°–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –≤—Å–µ—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ –≤–∞–∫–∞–Ω—Å–∏–π"""
        logger.info("–ù–∞—á–∏–Ω–∞—é —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤...")
        
        async with aiohttp.ClientSession() as session:
            parser = JobParser(session)
            
            for resource in self.resources:
                try:
                    jobs = []
                    
                    if resource['type'] == 'rss':
                        jobs = await parser.parse_rss(resource['url'], resource['name'])
                    elif resource['type'] == 'html':
                        jobs = await parser.parse_html(
                            resource['url'], 
                            resource['name'], 
                            resource.get('selectors', {})
                        )
                    
                    # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –∏ –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ –≤ –ë–î
                    for job in jobs:
                        self.stats['total_viewed'] += 1
                        
                        if self.job_filter.matches(job) and self.location_filter.is_location_allowed(job):
                            if self.db.add_job(job):
                                self.stats['total_added'] += 1
                                logger.info(f"–î–æ–±–∞–≤–ª–µ–Ω–∞ –≤–∞–∫–∞–Ω—Å–∏—è: {job.title}")
                    
                    logger.info(f"–û–±—Ä–∞–±–æ—Ç–∞–Ω –∏—Å—Ç–æ—á–Ω–∏–∫ {resource['name']}: {len(jobs)} –≤–∞–∫–∞–Ω—Å–∏–π")
                    
                except Exception as e:
                    logger.error(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏—Å—Ç–æ—á–Ω–∏–∫–∞ {resource['name']}: {e}")
        
        logger.info(f"–°–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ. –ü—Ä–æ—Å–º–æ—Ç—Ä–µ–Ω–æ: {self.stats['total_viewed']}, –¥–æ–±–∞–≤–ª–µ–Ω–æ: {self.stats['total_added']}")
    
    async def send_daily_report(self):
        """–û—Ç–ø—Ä–∞–≤–∫–∞ –µ–∂–µ–¥–Ω–µ–≤–Ω–æ–≥–æ –æ—Ç—á–µ—Ç–∞ –≤ Telegram"""
        logger.info("–û—Ç–ø—Ä–∞–≤–ª—è—é –µ–∂–µ–¥–Ω–µ–≤–Ω—ã–π –æ—Ç—á–µ—Ç...")
        
        new_jobs = self.db.get_new_jobs(24)
        
        if not new_jobs:
            await self.telegram_bot.send_message("üìã –ù–æ–≤—ã—Ö –≤–∞–∫–∞–Ω—Å–∏–π –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 24 —á–∞—Å–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ.")
            return
        
        # –°–æ–∑–¥–∞–Ω–∏–µ –µ–¥–∏–Ω–æ–≥–æ –¥–∞–π–¥–∂–µ—Å—Ç–∞
        digest = self.telegram_bot.create_digest(new_jobs, self.stats)
        
        # –û—Ç–ø—Ä–∞–≤–∫–∞ –¥–∞–π–¥–∂–µ—Å—Ç–∞ (–º–æ–∂–µ—Ç –±—ã—Ç—å —Ä–∞–∑–±–∏—Ç –Ω–∞ –Ω–µ—Å–∫–æ–ª—å–∫–æ —Å–æ–æ–±—â–µ–Ω–∏–π –µ—Å–ª–∏ —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã–π)
        sent_successfully = await self.telegram_bot.send_digest(digest)
        
        # –û—Ç–º–µ—Ç–∏—Ç—å –∫–∞–∫ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–µ –µ—Å–ª–∏ —É—Å–ø–µ—à–Ω–æ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ
        if sent_successfully:
            sent_hashes = [job.get_hash() for job in new_jobs]
            self.db.mark_as_sent(sent_hashes)
            logger.info(f"–î–∞–π–¥–∂–µ—Å—Ç –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω. –í–∞–∫–∞–Ω—Å–∏–π: {len(new_jobs)}")
        else:
            logger.error("–û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ –¥–∞–π–¥–∂–µ—Å—Ç–∞")

def create_example_configs():
    """–°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–∏–º–µ—Ä–æ–≤ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–æ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤"""
    
    # –ü—Ä–∏–º–µ—Ä resources.json
    resources_example = [
        {
            "name": "HackerNews Jobs",
            "type": "rss",
            "url": "https://hnrss.org/jobs"
        },
        {
            "name": "Indeed Jobs",
            "type": "html",
            "url": "https://indeed.com/jobs?q=python+developer",
            "selectors": {
                "container": ".job_seen_beacon",
                "title": ".jobTitle a span",
                "link": ".jobTitle a",
                "company": ".companyName",
                "location": ".companyLocation"
            }
        }
    ]
    
    keywords_example = [
        "python", "django", "flask", "remote", "junior", "senior",
        "backend", "fullstack", "developer", "engineer"
    ]
    
    if not os.path.exists('resources.json'):
        with open('resources.json', 'w', encoding='utf-8') as f:
            json.dump(resources_example, f, ensure_ascii=False, indent=2)
        logger.info("–°–æ–∑–¥–∞–Ω —Ñ–∞–π–ª resources.json")
    
    if not os.path.exists('keywords.json'):
        with open('keywords.json', 'w', encoding='utf-8') as f:
            json.dump(keywords_example, f, ensure_ascii=False, indent=2)
        logger.info("–°–æ–∑–¥–∞–Ω —Ñ–∞–π–ª keywords.json")
    
    if not os.path.exists('.env'):
        with open('.env', 'w') as f:
            f.write("TELEGRAM_BOT_TOKEN=your_bot_token_here\n")
            f.write("TELEGRAM_CHAT_ID=your_chat_id_here\n")
        logger.info("–°–æ–∑–¥–∞–Ω —Ñ–∞–π–ª .env")

async def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    parser = argparse.ArgumentParser(description='Job Monitor')
    parser.add_argument('--report', action='store_true', help='–û—Ç–ø—Ä–∞–≤–∏—Ç—å –µ–∂–µ–¥–Ω–µ–≤–Ω—ã–π –æ—Ç—á–µ—Ç')
    parser.add_argument('--scan', action='store_true', help='–í—ã–ø–æ–ª–Ω–∏—Ç—å —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ')
    parser.add_argument('--daemon', action='store_true', help='–ó–∞–ø—É—Å—Ç–∏—Ç—å –≤ —Ä–µ–∂–∏–º–µ –¥–µ–º–æ–Ω–∞')
    args = parser.parse_args()
    
    # –°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–∏–º–µ—Ä–æ–≤ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
    create_example_configs()
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è
    if not os.getenv('TELEGRAM_BOT_TOKEN') or not os.getenv('TELEGRAM_CHAT_ID'):
        logger.error("–ù–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω—ã –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è TELEGRAM_BOT_TOKEN –∏ TELEGRAM_CHAT_ID")
        return
    
    monitor = JobMonitor()
    
    if args.report:
        await monitor.send_daily_report()
    elif args.scan:
        await monitor.scan_all_sources()
    elif args.daemon:
        logger.info("–ó–∞–ø—É—Å–∫ –≤ —Ä–µ–∂–∏–º–µ –¥–µ–º–æ–Ω–∞...")
        
        # –ü–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–¥–∞—á
        schedule.every().hour.do(lambda: asyncio.run(monitor.scan_all_sources()))
        schedule.every().day.at("09:00").do(lambda: asyncio.run(monitor.send_daily_report()))
        
        logger.info("–î–µ–º–æ–Ω –∑–∞–ø—É—â–µ–Ω. –°–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–∞–∂–¥—ã–π —á–∞—Å, –æ—Ç—á–µ—Ç –≤ 9:00")
        
        while True:
            schedule.run_pending()
            time.sleep(60)
    else:
        # –†–∞–∑–æ–≤–æ–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ
        await monitor.scan_all_sources()
        await monitor.send_daily_report()

if __name__ == "__main__":
    try:
        asyncio.run(main())
    except RuntimeError as e:
        import sys
        if str(e).startswith("Event loop is closed") and sys.platform.startswith("win"):
            logger.warning("RuntimeError suppressed: Event loop is closed (Windows quirk)")
        else:
            raise
